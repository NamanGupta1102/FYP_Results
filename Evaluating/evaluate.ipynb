{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "# api_key = \"AIzaSyCuf-_Tq7gKStezexKTa2i2G8Ectg9xw8Q\" #saachi key\n",
    "api_key = \"AIzaSyBmjhopUEEOHLgBwvn0r36e3tsHUqOnEfA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading data: 100%|██████████| 57.6M/57.6M [00:09<00:00, 6.13MB/s]\n",
      "Generating train split: 4076 examples [00:00, 6040.36 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>after_merge</th>\n",
       "      <th>before_merge</th>\n",
       "      <th>source code and errors</th>\n",
       "      <th>full_traceback</th>\n",
       "      <th>traceback_type</th>\n",
       "      <th>secure_results</th>\n",
       "      <th>optimized_results</th>\n",
       "      <th>results</th>\n",
       "      <th>instruction_plus_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>def _smart_save(\\r\\n            self, fnam...</td>\n",
       "      <td>def _smart_save(self, fname, separately=No...</td>\n",
       "      <td>[{'piece_type': 'other', 'piece_content': 'def...</td>\n",
       "      <td>[INFO]  2018-01-21T20:44:59.613Z    f2689816-f...</td>\n",
       "      <td>FileNotFoundError</td>\n",
       "      <td>1. Use `pickle.HIGHEST_PROTOCOL` instead of `p...</td>\n",
       "      <td>1. Use `functools.lru_cache` to cache the resu...</td>\n",
       "      <td>1. Use `pickle.HIGHEST_PROTOCOL` instead of `p...</td>\n",
       "      <td>def _smart_save(self, fname, separately=No...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>def _smart_save(\\r\\n            self, fnam...</td>\n",
       "      <td>def _smart_save(self, fname, separately=No...</td>\n",
       "      <td>[{'piece_type': 'other', 'piece_content': 'def...</td>\n",
       "      <td>[INFO]  2018-01-21T20:44:59.613Z    f2689816-f...</td>\n",
       "      <td>FileNotFoundError</td>\n",
       "      <td>1. Use `pickle.HIGHEST_PROTOCOL` instead of `p...</td>\n",
       "      <td>1. Use `functools.lru_cache` to cache the resu...</td>\n",
       "      <td>1. Use `functools.lru_cache` to cache the resu...</td>\n",
       "      <td>def _smart_save(self, fname, separately=No...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>def save(\\r\\n            self, fname_or_ha...</td>\n",
       "      <td>def save(self, fname_or_handle, separately...</td>\n",
       "      <td>[{'piece_type': 'other', 'piece_content': 'def...</td>\n",
       "      <td>[INFO]  2018-01-21T20:44:59.613Z    f2689816-f...</td>\n",
       "      <td>FileNotFoundError</td>\n",
       "      <td>1. Use `with open()` to open the file in a con...</td>\n",
       "      <td>1. Use `functools.lru_cache` to cache the resu...</td>\n",
       "      <td>1. Use `with open()` to open the file in a con...</td>\n",
       "      <td>def save(self, fname_or_handle, separately...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>def save(\\r\\n            self, fname_or_ha...</td>\n",
       "      <td>def save(self, fname_or_handle, separately...</td>\n",
       "      <td>[{'piece_type': 'other', 'piece_content': 'def...</td>\n",
       "      <td>[INFO]  2018-01-21T20:44:59.613Z    f2689816-f...</td>\n",
       "      <td>FileNotFoundError</td>\n",
       "      <td>1. Use `with open()` to open the file in a con...</td>\n",
       "      <td>1. Use `functools.lru_cache` to cache the resu...</td>\n",
       "      <td>1. Use `functools.lru_cache` to cache the resu...</td>\n",
       "      <td>def save(self, fname_or_handle, separately...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>def pickle(obj, fname, protocol=PICKLE_PROTOCO...</td>\n",
       "      <td>def pickle(obj, fname, protocol=2):\\r\\n    \"\"\"...</td>\n",
       "      <td>[{'piece_type': 'other', 'piece_content': 'def...</td>\n",
       "      <td>[INFO]  2018-01-21T20:44:59.613Z    f2689816-f...</td>\n",
       "      <td>FileNotFoundError</td>\n",
       "      <td>1. Use a secure random number generator to gen...</td>\n",
       "      <td>1. Use `with` statement to open the file and a...</td>\n",
       "      <td>1. Use a secure random number generator to gen...</td>\n",
       "      <td>def pickle(obj, fname, protocol=2):\\r\\n    \"\"\"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                        after_merge  \\\n",
       "0   0      def _smart_save(\\r\\n            self, fnam...   \n",
       "1   0      def _smart_save(\\r\\n            self, fnam...   \n",
       "2   1      def save(\\r\\n            self, fname_or_ha...   \n",
       "3   1      def save(\\r\\n            self, fname_or_ha...   \n",
       "4   2  def pickle(obj, fname, protocol=PICKLE_PROTOCO...   \n",
       "\n",
       "                                        before_merge  \\\n",
       "0      def _smart_save(self, fname, separately=No...   \n",
       "1      def _smart_save(self, fname, separately=No...   \n",
       "2      def save(self, fname_or_handle, separately...   \n",
       "3      def save(self, fname_or_handle, separately...   \n",
       "4  def pickle(obj, fname, protocol=2):\\r\\n    \"\"\"...   \n",
       "\n",
       "                              source code and errors  \\\n",
       "0  [{'piece_type': 'other', 'piece_content': 'def...   \n",
       "1  [{'piece_type': 'other', 'piece_content': 'def...   \n",
       "2  [{'piece_type': 'other', 'piece_content': 'def...   \n",
       "3  [{'piece_type': 'other', 'piece_content': 'def...   \n",
       "4  [{'piece_type': 'other', 'piece_content': 'def...   \n",
       "\n",
       "                                      full_traceback     traceback_type  \\\n",
       "0  [INFO]  2018-01-21T20:44:59.613Z    f2689816-f...  FileNotFoundError   \n",
       "1  [INFO]  2018-01-21T20:44:59.613Z    f2689816-f...  FileNotFoundError   \n",
       "2  [INFO]  2018-01-21T20:44:59.613Z    f2689816-f...  FileNotFoundError   \n",
       "3  [INFO]  2018-01-21T20:44:59.613Z    f2689816-f...  FileNotFoundError   \n",
       "4  [INFO]  2018-01-21T20:44:59.613Z    f2689816-f...  FileNotFoundError   \n",
       "\n",
       "                                      secure_results  \\\n",
       "0  1. Use `pickle.HIGHEST_PROTOCOL` instead of `p...   \n",
       "1  1. Use `pickle.HIGHEST_PROTOCOL` instead of `p...   \n",
       "2  1. Use `with open()` to open the file in a con...   \n",
       "3  1. Use `with open()` to open the file in a con...   \n",
       "4  1. Use a secure random number generator to gen...   \n",
       "\n",
       "                                   optimized_results  \\\n",
       "0  1. Use `functools.lru_cache` to cache the resu...   \n",
       "1  1. Use `functools.lru_cache` to cache the resu...   \n",
       "2  1. Use `functools.lru_cache` to cache the resu...   \n",
       "3  1. Use `functools.lru_cache` to cache the resu...   \n",
       "4  1. Use `with` statement to open the file and a...   \n",
       "\n",
       "                                             results  \\\n",
       "0  1. Use `pickle.HIGHEST_PROTOCOL` instead of `p...   \n",
       "1  1. Use `functools.lru_cache` to cache the resu...   \n",
       "2  1. Use `with open()` to open the file in a con...   \n",
       "3  1. Use `functools.lru_cache` to cache the resu...   \n",
       "4  1. Use a secure random number generator to gen...   \n",
       "\n",
       "                               instruction_plus_code  \n",
       "0      def _smart_save(self, fname, separately=No...  \n",
       "1      def _smart_save(self, fname, separately=No...  \n",
       "2      def save(self, fname_or_handle, separately...  \n",
       "3      def save(self, fname_or_handle, separately...  \n",
       "4  def pickle(obj, fname, protocol=2):\\r\\n    \"\"\"...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"SKaup/same_column_secure_optimized_recommendations\")\n",
    "\n",
    "combined_df = pd.DataFrame()\n",
    "for split_name, split_data in dataset.items():\n",
    "  split_df = split_data.to_pandas()\n",
    "  combined_df = pd.concat([combined_df, split_df])\n",
    "\n",
    "df = combined_df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_code_optimized(buggy_code, recommendations):\n",
    "  time.sleep(3)\n",
    "  instruct = \"Here is a bad code, which is unoptimized. \\n\"\n",
    "  instruct2 = \"\\n Make the code more optimized based on the following recommendations. \\n\" \n",
    "  our_prompt = instruct  +  buggy_code + instruct2 + recommendations\n",
    "  \n",
    "  prompt = {\n",
    "      \"text\": our_prompt\n",
    "  }\n",
    "\n",
    "\n",
    "  raw = json.dumps({\"prompt\": prompt})\n",
    "\n",
    "\n",
    "  url = \"https://generativelanguage.googleapis.com/v1beta2/models/text-bison-001:generateText\"\n",
    "  params = {\"key\": api_key}\n",
    "  response = requests.post(url, params=params, data=raw)\n",
    "\n",
    "  if response.status_code == 200:\n",
    "      try:\n",
    "        data = response.json()\n",
    "        return data['candidates'][0]['output']\n",
    "      except:\n",
    "        print(\"Not working\")\n",
    "        print(data)\n",
    "        return \"000_Didnt Work\"\n",
    "  else:\n",
    "      print(f\"Error: {response.status_code}\")\n",
    "      return(\"000_Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_code_secure(buggy_code, recommendations):\n",
    "  time.sleep(3)\n",
    "  instruct = \"Here is a bad code, which is unsecure. \\n\"\n",
    "  instruct2 = \"\\n Make the code more secured based on the following recommendations. \\n\" \n",
    "  our_prompt = instruct  +  buggy_code + instruct2 + recommendations\n",
    "  \n",
    "  prompt = {\n",
    "      \"text\": our_prompt\n",
    "  }\n",
    "\n",
    "\n",
    "  raw = json.dumps({\"prompt\": prompt})\n",
    "\n",
    "\n",
    "  url = \"https://generativelanguage.googleapis.com/v1beta2/models/text-bison-001:generateText\"\n",
    "  params = {\"key\": api_key}\n",
    "  response = requests.post(url, params=params, data=raw)\n",
    "\n",
    "  if response.status_code == 200:\n",
    "      try:\n",
    "        data = response.json()\n",
    "        return data['candidates'][0]['output']\n",
    "      except:\n",
    "        print(\"Not working\")\n",
    "        print(data)\n",
    "        return \"000_Didnt Work\"\n",
    "  else:\n",
    "      print(f\"Error: {response.status_code}\")\n",
    "      return(\"000_Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_bleu_score_optimized():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_bleu_score_secure():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu_score_optimized():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu_score_secure():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['id','after_merge',\t'before_merge','source code and errors','full_traceback','traceback_type', 'secure_results','optimized_results',' results']\n",
    "with open('Recommend_optimized.csv', 'a+') as f_object:\n",
    "# obj = [ i, df['after_merge'][i], df['before_merge'][i], df['source code and errors'][i], df['full_traceback'][i], df['traceback_type'][i], df['secure_results'][i], opti ]\n",
    "        writer_object = writer(f_object)\n",
    "        writer_object.writerow(headers)\n",
    " \n",
    "    # Close the file object\n",
    "        f_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obj = ['id','after_merge',\t'before_merge','source code and errors','full_traceback','traceback_type', 'secure_results','optimied_results']\n",
    "with open('Recommend_optimized.csv', 'a+', encoding=\"utf-8\") as f_object:\n",
    "    for i in df.index[:]:\n",
    "        #palm: secure_code = gen_secure() \n",
    "        #palm: optimized_code = gen_optimized()\n",
    "        #codebleu: score = code_bleu_score()\n",
    "        #bleu score: bleu_score()\n",
    "\n",
    "\n",
    "        obj = [ i, df['after_merge'][i], df['before_merge'][i], df['source code and errors'][i], df['full_traceback'][i], df['traceback_type'][i], df['secure_results'][i], opti ]\n",
    "        writer_object = writer(f_object)\n",
    "        writer_object.writerow(obj)\n",
    "        print(i)\n",
    " \n",
    "    # Close the file object\n",
    "    f_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
