{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "api_key = \"AIzaSyBmjhopUEEOHLgBwvn0r36e3tsHUqOnEfA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a11ec1721a1245deb7f035ab63e5bbbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.53M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d07165fafa6c40848710da02504c0ab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"SKaup/test_data_before_and_after_merge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>after_merge</th>\n",
       "      <th>before_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>def cmdb_get_mainline_object_topo(request, bk_...</td>\n",
       "      <td>def cmdb_get_mainline_object_topo(request, bk_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>def cc_search_object_attribute(request, obj_id...</td>\n",
       "      <td>def cc_search_object_attribute(request, obj_id...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>def cc_search_create_object_attribute(request,...</td>\n",
       "      <td>def cc_search_create_object_attribute(request,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>def cc_search_topo(request, obj_id, category, ...</td>\n",
       "      <td>def cc_search_topo(request, obj_id, category, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>def job_get_script_list(request, biz_cc_id):\\n...</td>\n",
       "      <td>def job_get_script_list(request, biz_cc_id):\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         after_merge  \\\n",
       "0  def cmdb_get_mainline_object_topo(request, bk_...   \n",
       "1  def cc_search_object_attribute(request, obj_id...   \n",
       "2  def cc_search_create_object_attribute(request,...   \n",
       "3  def cc_search_topo(request, obj_id, category, ...   \n",
       "4  def job_get_script_list(request, biz_cc_id):\\n...   \n",
       "\n",
       "                                        before_merge  \n",
       "0  def cmdb_get_mainline_object_topo(request, bk_...  \n",
       "1  def cc_search_object_attribute(request, obj_id...  \n",
       "2  def cc_search_create_object_attribute(request,...  \n",
       "3  def cc_search_topo(request, obj_id, category, ...  \n",
       "4  def job_get_script_list(request, biz_cc_id):\\n...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = pd.DataFrame()\n",
    "for split_name, split_data in dataset.items():\n",
    "  split_df = split_data.to_pandas()\n",
    "  combined_df = pd.concat([combined_df, split_df])\n",
    "\n",
    "df = combined_df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'simpleT5'...\n",
      "remote: Enumerating objects: 315, done.\u001b[K\n",
      "remote: Counting objects: 100% (107/107), done.\u001b[K\n",
      "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
      "remote: Total 315 (delta 79), reused 73 (delta 71), pack-reused 208\u001b[K\n",
      "Receiving objects: 100% (315/315), 377.73 KiB | 37.00 KiB/s, done.\n",
      "Resolving deltas: 100% (146/146), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Shivanandroy/simpleT5.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /home/saachi/.local/lib/python3.10/site-packages (from -r simpleT5/requirements.txt (line 1)) (1.26.0)\n",
      "Requirement already satisfied: pandas in /home/saachi/.local/lib/python3.10/site-packages (from -r simpleT5/requirements.txt (line 2)) (1.5.3)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch!=1.8.0,>=1.7.0 in /home/saachi/.local/lib/python3.10/site-packages (from -r simpleT5/requirements.txt (line 4)) (2.1.2)\n",
      "Collecting transformers==4.16.2\n",
      "  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting pytorch-lightning==1.5.10\n",
      "  Downloading pytorch_lightning-1.5.10-py3-none-any.whl (527 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.7/527.7 KB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/saachi/.local/lib/python3.10/site-packages (from transformers==4.16.2->-r simpleT5/requirements.txt (line 5)) (3.13.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers==4.16.2->-r simpleT5/requirements.txt (line 5)) (5.4.1)\n",
      "Requirement already satisfied: requests in /home/saachi/.local/lib/python3.10/site-packages (from transformers==4.16.2->-r simpleT5/requirements.txt (line 5)) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/saachi/.local/lib/python3.10/site-packages (from transformers==4.16.2->-r simpleT5/requirements.txt (line 5)) (4.66.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/saachi/.local/lib/python3.10/site-packages (from transformers==4.16.2->-r simpleT5/requirements.txt (line 5)) (23.1)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 KB\u001b[0m \u001b[31m782.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /home/saachi/.local/lib/python3.10/site-packages (from transformers==4.16.2->-r simpleT5/requirements.txt (line 5)) (0.15.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/saachi/.local/lib/python3.10/site-packages (from transformers==4.16.2->-r simpleT5/requirements.txt (line 5)) (0.20.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/saachi/.local/lib/python3.10/site-packages (from transformers==4.16.2->-r simpleT5/requirements.txt (line 5)) (2023.8.8)\n",
      "Collecting tensorboard>=2.2.0\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyDeprecate==0.3.1\n",
      "  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /home/saachi/.local/lib/python3.10/site-packages (from pytorch-lightning==1.5.10->-r simpleT5/requirements.txt (line 6)) (2023.12.2)\n",
      "Collecting torchmetrics>=0.4.1\n",
      "  Downloading torchmetrics-1.3.2-py3-none-any.whl (841 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m841.5/841.5 KB\u001b[0m \u001b[31m877.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /home/saachi/.local/lib/python3.10/site-packages (from pytorch-lightning==1.5.10->-r simpleT5/requirements.txt (line 6)) (4.9.0)\n",
      "Collecting setuptools==59.5.0\n",
      "  Downloading setuptools-59.5.0-py3-none-any.whl (952 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m952.4/952.4 KB\u001b[0m \u001b[31m935.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m912.4 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting future>=0.17.1\n",
      "  Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.3/491.3 KB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /home/saachi/.local/lib/python3.10/site-packages (from pandas->-r simpleT5/requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->-r simpleT5/requirements.txt (line 2)) (2022.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/saachi/.local/lib/python3.10/site-packages (from torch!=1.8.0,>=1.7.0->-r simpleT5/requirements.txt (line 4)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/saachi/.local/lib/python3.10/site-packages (from torch!=1.8.0,>=1.7.0->-r simpleT5/requirements.txt (line 4)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/saachi/.local/lib/python3.10/site-packages (from torch!=1.8.0,>=1.7.0->-r simpleT5/requirements.txt (line 4)) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/saachi/.local/lib/python3.10/site-packages (from torch!=1.8.0,>=1.7.0->-r simpleT5/requirements.txt (line 4)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/saachi/.local/lib/python3.10/site-packages (from torch!=1.8.0,>=1.7.0->-r simpleT5/requirements.txt (line 4)) (8.9.2.26)\n",
      "Requirement already satisfied: networkx in /home/saachi/.local/lib/python3.10/site-packages (from torch!=1.8.0,>=1.7.0->-r simpleT5/requirements.txt (line 4)) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/saachi/.local/lib/python3.10/site-packages (from torch!=1.8.0,>=1.7.0->-r simpleT5/requirements.txt (line 4)) (12.1.105)\n",
      "Requirement already satisfied: jinja2 in /home/saachi/.local/lib/python3.10/site-packages (from torch!=1.8.0,>=1.7.0->-r simpleT5/requirements.txt (line 4)) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/saachi/.local/lib/python3.10/site-packages (from torch!=1.8.0,>=1.7.0->-r simpleT5/requirements.txt (line 4)) (11.0.2.54)\n",
      "Requirement already satisfied: sympy in /home/saachi/.local/lib/python3.10/site-packages (from torch!=1.8.0,>=1.7.0->-r simpleT5/requirements.txt (line 4)) (1.12)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/saachi/.local/lib/python3.10/site-packages (from torch!=1.8.0,>=1.7.0->-r simpleT5/requirements.txt (line 4)) (2.1.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/saachi/.local/lib/python3.10/site-packages (from torch!=1.8.0,>=1.7.0->-r simpleT5/requirements.txt (line 4)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/saachi/.local/lib/python3.10/site-packages (from torch!=1.8.0,>=1.7.0->-r simpleT5/requirements.txt (line 4)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/saachi/.local/lib/python3.10/site-packages (from torch!=1.8.0,>=1.7.0->-r simpleT5/requirements.txt (line 4)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/saachi/.local/lib/python3.10/site-packages (from torch!=1.8.0,>=1.7.0->-r simpleT5/requirements.txt (line 4)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/saachi/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch!=1.8.0,>=1.7.0->-r simpleT5/requirements.txt (line 4)) (12.3.101)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/saachi/.local/lib/python3.10/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10->-r simpleT5/requirements.txt (line 6)) (3.9.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->-r simpleT5/requirements.txt (line 2)) (1.16.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /home/saachi/.local/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10->-r simpleT5/requirements.txt (line 6)) (4.25.3)\n",
      "Collecting grpcio>=1.48.2\n",
      "  Downloading grpcio-1.62.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /home/saachi/.local/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10->-r simpleT5/requirements.txt (line 6)) (3.5.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/saachi/.local/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10->-r simpleT5/requirements.txt (line 6)) (3.0.1)\n",
      "Collecting absl-py>=0.4\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 KB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting lightning-utilities>=0.8.0\n",
      "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/saachi/.local/lib/python3.10/site-packages (from jinja2->torch!=1.8.0,>=1.7.0->-r simpleT5/requirements.txt (line 4)) (2.1.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->transformers==4.16.2->-r simpleT5/requirements.txt (line 5)) (1.26.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers==4.16.2->-r simpleT5/requirements.txt (line 5)) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/saachi/.local/lib/python3.10/site-packages (from requests->transformers==4.16.2->-r simpleT5/requirements.txt (line 5)) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers==4.16.2->-r simpleT5/requirements.txt (line 5)) (2020.6.20)\n",
      "Requirement already satisfied: joblib in /home/saachi/.local/lib/python3.10/site-packages (from sacremoses->transformers==4.16.2->-r simpleT5/requirements.txt (line 5)) (1.3.2)\n",
      "Requirement already satisfied: click in /home/saachi/.local/lib/python3.10/site-packages (from sacremoses->transformers==4.16.2->-r simpleT5/requirements.txt (line 5)) (8.1.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/saachi/.local/lib/python3.10/site-packages (from sympy->torch!=1.8.0,>=1.7.0->-r simpleT5/requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/saachi/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10->-r simpleT5/requirements.txt (line 6)) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/saachi/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10->-r simpleT5/requirements.txt (line 6)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/saachi/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10->-r simpleT5/requirements.txt (line 6)) (6.0.5)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/saachi/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10->-r simpleT5/requirements.txt (line 6)) (4.0.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/saachi/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10->-r simpleT5/requirements.txt (line 6)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/lib/python3/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10->-r simpleT5/requirements.txt (line 6)) (21.2.0)\n",
      "Installing collected packages: sentencepiece, tensorboard-data-server, setuptools, sacremoses, pyDeprecate, grpcio, future, absl-py, tensorboard, lightning-utilities, transformers, torchmetrics, pytorch-lightning\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 69.2.0\n",
      "    Uninstalling setuptools-69.2.0:\n",
      "      Successfully uninstalled setuptools-69.2.0\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.37.0.dev0\n",
      "    Uninstalling transformers-4.37.0.dev0:\n",
      "      Successfully uninstalled transformers-4.37.0.dev0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "codebleu 0.4.0 requires setuptools>=61.0.0, but you have setuptools 59.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed absl-py-2.1.0 future-1.0.0 grpcio-1.62.1 lightning-utilities-0.11.2 pyDeprecate-0.3.1 pytorch-lightning-1.5.10 sacremoses-0.1.1 sentencepiece-0.2.0 setuptools-59.5.0 tensorboard-2.16.2 tensorboard-data-server-0.7.2 torchmetrics-1.3.2 transformers-4.16.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -r simpleT5/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saachi/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n",
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "import simpleT5.simplet5.simplet5 as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_codeT5 = sp.SimpleT5()\n",
    "model_T5 = sp.SimpleT5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "836fee7c75c243ffac6aa62915def07e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.49k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "038438298dc94d9bba31fa8205e3d456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/231M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38705ce991c244329b6fdf01459fed4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.41k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61fa49c810d341dcb7c8d0c9c6099c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/562k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f67a8cdfa2064366a9eabb6a838fa117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/287k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56c53b88ccf64f95b3dee3aafca34100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/12.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model_codeT5.from_pretrained(\"codet5\",\"SKaup/Explore_Upload\")\n",
    "model_codeT5.load_model(\"codet5\",\"SKaup/code_t5_small_optimized_secured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. **Use `input()` instead of `input()` to avoid unnecessary code parsing.** This will prevent the code from being executed multiple times. For example, you can use a more efficient data structure. Example: this will make the code more concise and easier to read.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_codeT5.predict('eval(input(\"<code>\"))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e5770a3db224befb384983f5bd56dd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.35k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f649a3a6422940ffaf21821e5460db16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/231M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22efeb5903b242e49743534f01482d3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.92k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "868ef72e72db46e0b2319795ab3d78bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/773k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddbb54d84e674babb3a94ede729fbd3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ffc051f889542fd9c69f901001e4cc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.74k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_T5.load_model(\"t5\", \"SKaup/t5_small_optimized_secured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. Use eval() to check the input value.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_T5.predict('eval(input(\"<code>\"))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendation_secure(model, buggy_code):\n",
    "    instruct = '''\\n Give a recommendation for making this code more secured:\\n\n",
    "              Give me the most important 3 points to Secure this code.\\n\n",
    "              Answer in three sentences only, and be specific.'''\n",
    "    prompt = buggy_code + instruct \n",
    "    return model.predict(prompt)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendation_optimize(model, buggy_code):\n",
    "    instruct = '''\\n Give a recommendation for making this code more Optimized:\\n\n",
    "            Give me the most important 3 points to Optimize this code.\\n\n",
    "            Answer in three sentences only, and be specific.'''\n",
    "    prompt = buggy_code + instruct \n",
    "    return model.predict(prompt)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_bleu_score_optimized():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_bleu_score():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu_score_secure():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [\"index\",'after_merge', 'before_merge', 'secure_results_codeT5','optimized_results_codeT5', 'secure_results_T5' ,'optimized_results_T5' ]\n",
    "with open('evaluating_codeT5.csv', 'a+') as f_object:\n",
    "# obj = [ i, df['after_merge'][i], df['before_merge'][i], df['source code and errors'][i], df['full_traceback'][i], df['traceback_type'][i], df['secure_results'][i], opti ]\n",
    "        writer_object = writer(f_object)\n",
    "        writer_object.writerow(headers)\n",
    " \n",
    "    # Close the file object\n",
    "        f_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (555 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (857 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "# obj = ['id','after_merge',\t'before_merge','source code and errors','full_traceback','traceback_type', 'secure_results','optimied_results']\n",
    "with open('evaluating_codeT5.csv', 'a+', encoding=\"utf-8\") as f_object:\n",
    "    for i in df.index[100:201]:\n",
    "        #palm: secure_code = gen_secure() \n",
    "        #palm: optimized_code = gen_optimized()\n",
    "        #codebleu: score = code_bleu_score()\n",
    "        #bleu score: bleu_score()\n",
    "        secure_results_codeT5 = recommendation_secure(model_codeT5,df['before_merge'][i])\n",
    "        optimized_results_codeT5 = recommendation_optimize(model_codeT5,df['before_merge'][i])\n",
    "        secure_results_T5 = recommendation_secure(model_T5,df['before_merge'][i])\n",
    "        optimized_results_T5 =recommendation_optimize(model_T5,df['before_merge'][i])\n",
    "        row = [i, df['after_merge'][i],\tdf['before_merge'][i], secure_results_codeT5,optimized_results_codeT5, secure_results_T5 ,optimized_results_T5]\n",
    "        writer_object = writer(f_object)\n",
    "        writer_object.writerow(row)\n",
    "        print(i)\n",
    " \n",
    "    # Close the file object\n",
    "    f_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>after_merge</th>\n",
       "      <th>before_merge</th>\n",
       "      <th>secure_results_codeT5</th>\n",
       "      <th>optimized_results_codeT5</th>\n",
       "      <th>secure_results_T5</th>\n",
       "      <th>optimized_results_T5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>def send(self, data):\\n        \"\"\"Send dat...</td>\n",
       "      <td>def send(self, data):\\n        \"\"\"Send dat...</td>\n",
       "      <td>1. Use `socket.gather()` instead of `self.sock...</td>\n",
       "      <td>1. Use `socket.recv()` instead of `self.sock.r...</td>\n",
       "      <td>1. Use functools.lru_cache to cache the result...</td>\n",
       "      <td>1. **Use functools.lru_cache to cache the resu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>def _find_worker(relative, follow, done, work,...</td>\n",
       "      <td>def _find_worker(relative, follow, done, work,...</td>\n",
       "      <td>1. Use `os.path.relpath()` instead of `os.path...</td>\n",
       "      <td>1. Use `functools.lru_cache` to cache the resu...</td>\n",
       "      <td>1. Use functools.lru_cache to cache the result...</td>\n",
       "      <td>1. Use functools.lru_cache to cache the result...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102</td>\n",
       "      <td>def push(self, buffer_):\\n        if self....</td>\n",
       "      <td>def push(self, buffer_):\\n        if buffe...</td>\n",
       "      <td>1. Use `gst_source.emit('end-of-stream', buffe...</td>\n",
       "      <td>1. Use `gst_source.emit('end-of-stream', buffe...</td>\n",
       "      <td>1. Use functools.lru_cache to cache the result...</td>\n",
       "      <td>1. **Use functools.partial to avoid repeating ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103</td>\n",
       "      <td>def find_exact(tracks, query=None, uris=None):...</td>\n",
       "      <td>def find_exact(tracks, query=None, uris=None):...</td>\n",
       "      <td>1. Use `functools.lru_cache` to cache the resu...</td>\n",
       "      <td>1. Use `functools.lru_cache` to cache the resu...</td>\n",
       "      <td>1. Use functools.lru_cache to cache the result...</td>\n",
       "      <td>1. Use functools.lru_cache to cache the result...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104</td>\n",
       "      <td>def validate_extension(extension):\\n    \"\"\"Ver...</td>\n",
       "      <td>def validate_extension(extension):\\n    \"\"\"Ver...</td>\n",
       "      <td>1. Use `functools.lru_cache` to cache the resu...</td>\n",
       "      <td>1. Use `functools.lru_cache` to cache the resu...</td>\n",
       "      <td>1. Use functools.lru_cache to cache the result...</td>\n",
       "      <td>1. Use functools.lru_cache to cache the result...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                        after_merge  \\\n",
       "0    100      def send(self, data):\\n        \"\"\"Send dat...   \n",
       "1    101  def _find_worker(relative, follow, done, work,...   \n",
       "2    102      def push(self, buffer_):\\n        if self....   \n",
       "3    103  def find_exact(tracks, query=None, uris=None):...   \n",
       "4    104  def validate_extension(extension):\\n    \"\"\"Ver...   \n",
       "\n",
       "                                        before_merge  \\\n",
       "0      def send(self, data):\\n        \"\"\"Send dat...   \n",
       "1  def _find_worker(relative, follow, done, work,...   \n",
       "2      def push(self, buffer_):\\n        if buffe...   \n",
       "3  def find_exact(tracks, query=None, uris=None):...   \n",
       "4  def validate_extension(extension):\\n    \"\"\"Ver...   \n",
       "\n",
       "                               secure_results_codeT5  \\\n",
       "0  1. Use `socket.gather()` instead of `self.sock...   \n",
       "1  1. Use `os.path.relpath()` instead of `os.path...   \n",
       "2  1. Use `gst_source.emit('end-of-stream', buffe...   \n",
       "3  1. Use `functools.lru_cache` to cache the resu...   \n",
       "4  1. Use `functools.lru_cache` to cache the resu...   \n",
       "\n",
       "                            optimized_results_codeT5  \\\n",
       "0  1. Use `socket.recv()` instead of `self.sock.r...   \n",
       "1  1. Use `functools.lru_cache` to cache the resu...   \n",
       "2  1. Use `gst_source.emit('end-of-stream', buffe...   \n",
       "3  1. Use `functools.lru_cache` to cache the resu...   \n",
       "4  1. Use `functools.lru_cache` to cache the resu...   \n",
       "\n",
       "                                   secure_results_T5  \\\n",
       "0  1. Use functools.lru_cache to cache the result...   \n",
       "1  1. Use functools.lru_cache to cache the result...   \n",
       "2  1. Use functools.lru_cache to cache the result...   \n",
       "3  1. Use functools.lru_cache to cache the result...   \n",
       "4  1. Use functools.lru_cache to cache the result...   \n",
       "\n",
       "                                optimized_results_T5  \n",
       "0  1. **Use functools.lru_cache to cache the resu...  \n",
       "1  1. Use functools.lru_cache to cache the result...  \n",
       "2  1. **Use functools.partial to avoid repeating ...  \n",
       "3  1. Use functools.lru_cache to cache the result...  \n",
       "4  1. Use functools.lru_cache to cache the result...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_code_t5_and_t5_recommendations = pd.read_csv('evaluating_codeT5.csv')\n",
    "df_code_t5_and_t5_recommendations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def palm_optimized_code(buggy_code, recommendations):\n",
    "  time.sleep(2)\n",
    "  instruct = \"Here is a bad code, which is unoptimized. \\n\"\n",
    "  instruct2 = \"\\n Make the code more optimized based on the following recommendations. \\n\" \n",
    "  our_prompt = instruct  +  buggy_code + instruct2 + recommendations\n",
    "  \n",
    "  prompt = {\n",
    "      \"text\": our_prompt\n",
    "  }\n",
    "\n",
    "\n",
    "  raw = json.dumps({\"prompt\": prompt})\n",
    "\n",
    "\n",
    "  url = \"https://generativelanguage.googleapis.com/v1beta2/models/text-bison-001:generateText\"\n",
    "  params = {\"key\": api_key}\n",
    "  response = requests.post(url, params=params, data=raw)\n",
    "\n",
    "  if response.status_code == 200:\n",
    "      try:\n",
    "        data = response.json()\n",
    "        return data['candidates'][0]['output']\n",
    "      except:\n",
    "        print(\"Not working\")\n",
    "        print(data)\n",
    "        return \"000_Didnt Work\"\n",
    "  else:\n",
    "      print(f\"Error: {response.status_code}\")\n",
    "      return(\"000_Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def palm_secure_code(buggy_code, recommendations):\n",
    "  time.sleep(2)\n",
    "  instruct = \"Here is a bad code, which is unsecure. \\n\"\n",
    "  instruct2 = \"\\n Make the code more secured based on the following recommendations. \\n\" \n",
    "  our_prompt = instruct  +  buggy_code + instruct2 + recommendations\n",
    "  \n",
    "  prompt = {\n",
    "      \"text\": our_prompt\n",
    "  }\n",
    "\n",
    "\n",
    "  raw = json.dumps({\"prompt\": prompt})\n",
    "\n",
    "\n",
    "  url = \"https://generativelanguage.googleapis.com/v1beta2/models/text-bison-001:generateText\"\n",
    "  params = {\"key\": api_key}\n",
    "  response = requests.post(url, params=params, data=raw)\n",
    "\n",
    "  if response.status_code == 200:\n",
    "      try:\n",
    "        data = response.json()\n",
    "        return data['candidates'][0]['output']\n",
    "      except:\n",
    "        print(\"Not working\")\n",
    "        print(data)\n",
    "        return \"000_Didnt Work\"\n",
    "  else:\n",
    "      print(f\"Error: {response.status_code}\")\n",
    "      return(\"000_Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_code_t5_and_t5_recommendations['secure_from_codeT5_recommendations'] = None\n",
    "df_code_t5_and_t5_recommendations['optimize_from_codeT5_recommendations'] = None\n",
    "df_code_t5_and_t5_recommendations['secure_from_T5_recommendations'] = None\n",
    "df_code_t5_and_t5_recommendations['optimize_from_T5_recommendations'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>after_merge</th>\n",
       "      <th>before_merge</th>\n",
       "      <th>secure_results_codeT5</th>\n",
       "      <th>optimized_results_codeT5</th>\n",
       "      <th>secure_results_T5</th>\n",
       "      <th>optimized_results_T5</th>\n",
       "      <th>secure_from_codeT5_recommendations</th>\n",
       "      <th>optimize_from_codeT5_recommendations</th>\n",
       "      <th>secure_from_T5_recommendations</th>\n",
       "      <th>optimize_from_T5_recommendations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>def send(self, data):\\n        \"\"\"Send dat...</td>\n",
       "      <td>def send(self, data):\\n        \"\"\"Send dat...</td>\n",
       "      <td>1. Use `socket.gather()` instead of `self.sock...</td>\n",
       "      <td>1. Use `socket.recv()` instead of `self.sock.r...</td>\n",
       "      <td>1. Use functools.lru_cache to cache the result...</td>\n",
       "      <td>1. **Use functools.lru_cache to cache the resu...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>def _find_worker(relative, follow, done, work,...</td>\n",
       "      <td>def _find_worker(relative, follow, done, work,...</td>\n",
       "      <td>1. Use `os.path.relpath()` instead of `os.path...</td>\n",
       "      <td>1. Use `functools.lru_cache` to cache the resu...</td>\n",
       "      <td>1. Use functools.lru_cache to cache the result...</td>\n",
       "      <td>1. Use functools.lru_cache to cache the result...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102</td>\n",
       "      <td>def push(self, buffer_):\\n        if self....</td>\n",
       "      <td>def push(self, buffer_):\\n        if buffe...</td>\n",
       "      <td>1. Use `gst_source.emit('end-of-stream', buffe...</td>\n",
       "      <td>1. Use `gst_source.emit('end-of-stream', buffe...</td>\n",
       "      <td>1. Use functools.lru_cache to cache the result...</td>\n",
       "      <td>1. **Use functools.partial to avoid repeating ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103</td>\n",
       "      <td>def find_exact(tracks, query=None, uris=None):...</td>\n",
       "      <td>def find_exact(tracks, query=None, uris=None):...</td>\n",
       "      <td>1. Use `functools.lru_cache` to cache the resu...</td>\n",
       "      <td>1. Use `functools.lru_cache` to cache the resu...</td>\n",
       "      <td>1. Use functools.lru_cache to cache the result...</td>\n",
       "      <td>1. Use functools.lru_cache to cache the result...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104</td>\n",
       "      <td>def validate_extension(extension):\\n    \"\"\"Ver...</td>\n",
       "      <td>def validate_extension(extension):\\n    \"\"\"Ver...</td>\n",
       "      <td>1. Use `functools.lru_cache` to cache the resu...</td>\n",
       "      <td>1. Use `functools.lru_cache` to cache the resu...</td>\n",
       "      <td>1. Use functools.lru_cache to cache the result...</td>\n",
       "      <td>1. Use functools.lru_cache to cache the result...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                        after_merge  \\\n",
       "0    100      def send(self, data):\\n        \"\"\"Send dat...   \n",
       "1    101  def _find_worker(relative, follow, done, work,...   \n",
       "2    102      def push(self, buffer_):\\n        if self....   \n",
       "3    103  def find_exact(tracks, query=None, uris=None):...   \n",
       "4    104  def validate_extension(extension):\\n    \"\"\"Ver...   \n",
       "\n",
       "                                        before_merge  \\\n",
       "0      def send(self, data):\\n        \"\"\"Send dat...   \n",
       "1  def _find_worker(relative, follow, done, work,...   \n",
       "2      def push(self, buffer_):\\n        if buffe...   \n",
       "3  def find_exact(tracks, query=None, uris=None):...   \n",
       "4  def validate_extension(extension):\\n    \"\"\"Ver...   \n",
       "\n",
       "                               secure_results_codeT5  \\\n",
       "0  1. Use `socket.gather()` instead of `self.sock...   \n",
       "1  1. Use `os.path.relpath()` instead of `os.path...   \n",
       "2  1. Use `gst_source.emit('end-of-stream', buffe...   \n",
       "3  1. Use `functools.lru_cache` to cache the resu...   \n",
       "4  1. Use `functools.lru_cache` to cache the resu...   \n",
       "\n",
       "                            optimized_results_codeT5  \\\n",
       "0  1. Use `socket.recv()` instead of `self.sock.r...   \n",
       "1  1. Use `functools.lru_cache` to cache the resu...   \n",
       "2  1. Use `gst_source.emit('end-of-stream', buffe...   \n",
       "3  1. Use `functools.lru_cache` to cache the resu...   \n",
       "4  1. Use `functools.lru_cache` to cache the resu...   \n",
       "\n",
       "                                   secure_results_T5  \\\n",
       "0  1. Use functools.lru_cache to cache the result...   \n",
       "1  1. Use functools.lru_cache to cache the result...   \n",
       "2  1. Use functools.lru_cache to cache the result...   \n",
       "3  1. Use functools.lru_cache to cache the result...   \n",
       "4  1. Use functools.lru_cache to cache the result...   \n",
       "\n",
       "                                optimized_results_T5  \\\n",
       "0  1. **Use functools.lru_cache to cache the resu...   \n",
       "1  1. Use functools.lru_cache to cache the result...   \n",
       "2  1. **Use functools.partial to avoid repeating ...   \n",
       "3  1. Use functools.lru_cache to cache the result...   \n",
       "4  1. Use functools.lru_cache to cache the result...   \n",
       "\n",
       "  secure_from_codeT5_recommendations optimize_from_codeT5_recommendations  \\\n",
       "0                               None                                 None   \n",
       "1                               None                                 None   \n",
       "2                               None                                 None   \n",
       "3                               None                                 None   \n",
       "4                               None                                 None   \n",
       "\n",
       "  secure_from_T5_recommendations optimize_from_T5_recommendations  \n",
       "0                           None                             None  \n",
       "1                           None                             None  \n",
       "2                           None                             None  \n",
       "3                           None                             None  \n",
       "4                           None                             None  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_code_t5_and_t5_recommendations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [\"index\",'after_merge', 'before_merge', 'secure_results_codeT5','optimized_results_codeT5', 'secure_results_T5' ,'optimized_results_T5', 'secure_from_codeT5_recommendations', 'optimize_from_codeT5_recommendations', 'secure_from_T5_recommendations', 'optimize_from_T5_recommendations']\n",
    "with open('palm_code_from_recommendations.csv', 'a+') as f_object:\n",
    "# obj = [ i, df['after_merge'][i], df['before_merge'][i], df['source code and errors'][i], df['full_traceback'][i], df['traceback_type'][i], df['secure_results'][i], opti ]\n",
    "        writer_object = writer(f_object)\n",
    "        writer_object.writerow(headers)\n",
    " \n",
    "    # Close the file object\n",
    "        f_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[102, \"    def push(self, buffer_):\\n        if self._source is None:\\n            return False\\n\\n        if buffer_ is None:\\n            gst_logger.debug('Sending appsrc end-of-stream event.')\\n            return self._source.emit('end-of-stream') == gst.FLOW_OK\\n        else:\\n            return self._source.emit('push-buffer', buffer_) == gst.FLOW_OK\", \"    def push(self, buffer_):\\n        if buffer_ is None:\\n            gst_logger.debug('Sending appsrc end-of-stream event.')\\n            return self._source.emit('end-of-stream') == gst.FLOW_OK\\n        else:\\n            return self._source.emit('push-buffer', buffer_) == gst.FLOW_OK\", \"1. Use `gst_source.emit('end-of-stream', buffer_)` instead of `gst_logger.debug(`Sending appsrc end-of-stream event to the server.\\n2. Use `gst_source.emit('push-buffer', buffer_)` instead of `gst_source.emit('push-buffer', buffer_)` to avoid unnecessary function calls.\\n3. Use `gst_source.emit('push-buffer', buffer_)` instead of `gst_source.emit('push-buffer', buffer_) == gst.FLOW_OK`.\", \"1. Use `gst_source.emit('end-of-stream', buffer_)` instead of `gst_logger.debug(`Sending appsrc end-of-stream event to the server.\\n2. Use `gst_source.emit('push-buffer', buffer_)` instead of `gst_source.emit('push-buffer', buffer_)` to avoid unnecessary function calls.\\n3. Use `gst_source.emit('push-buffer', buffer_)` instead of `gst_source.emit('push-buffer', buffer_) == gst.FLOW_OK`.\", '1. Use functools.lru_cache to cache the results of gst_logger.debug and gst_logger.debug. 2. Use django.python.get() to check if the buffer is None. 3. Use django.python.get() to get the buffer from the apprc end-of-stream event.', '1. **Use functools.partial to avoid repeating arguments.** This will make the code more concise and easier to read. 2. **Use torch.jit.script to create a new function for each apprc event.** This will make the code more concise and easier to read. 3. **Use torch.jit.get() to check if the buffer is None.** This will improve performance.', \"```python\\ndef push(self, buffer_):\\n    if buffer_ is None:\\n        gst_source.emit('end-of-stream', buffer_)\\n    else:\\n        gst_source.emit('push-buffer', buffer_)\\n```\", \"```python\\ndef push(self, buffer_):\\n    if buffer_ is None:\\n        return self._source.emit('end-of-stream', buffer_)\\n    else:\\n        return self._source.emit('push-buffer', buffer_)\\n```\", \"```python\\ndef push(self, buffer_):\\n    @functools.lru_cache(maxsize=1024)\\n    def gst_logger_debug(msg):\\n        return gst_logger.debug(msg)\\n\\n    @functools.lru_cache(maxsize=1024)\\n    def django_python_get(obj):\\n        return django.python.get(obj)\\n\\n    if buffer_ is None:\\n        gst_logger_debug('Sending appsrc end-of-stream event.')\\n        return self._source.emit('end-of-stream') == gst.FLOW_OK\\n    else:\\n        return self._source.emit('push-buffer', buffer_) == gst.FLOW_OK\\n```\", '```python\\nimport functools\\nimport torch\\nimport torch.jit\\n\\nfrom torch.utils.cpp_extension import load\\n\\ngst_logger = logging.getLogger(\\'gst\\')\\n\\n\\ndef push(source, buffer):\\n    \"\"\"Push a buffer to an appsrc element.\\n\\n    Args:\\n        source (Gst.Element): The appsrc element to push the buffer to.\\n        buffer (torch.Tensor): The buffer to push.\\n\\n    Returns:\\n        bool: True if the buffer was successfully pushed, False otherwise.\\n    \"\"\"\\n\\n    if buffer is None:\\n        gst_logger.debug(\\'Sending appsrc end-of-stream event.\\')\\n        return source.emit(\\'end-of-stream\\') == gst.FLOW_OK\\n    else:\\n        return source.emit(\\'push-buffer\\', buffer) == gst.FLOW_OK\\n\\n\\ndef _push_buffer(source, buffer):\\n    \"\"\"Push a buffer to an appsrc element.\\n\\n    This function is a Python wrapper for the `push` function. It is used to\\n    create a new function for each apprc event, which improves performance.\\n\\n    Args:\\n        source (Gst.Element): The appsrc element to push the buffer to.\\n        buffer (torch.Tensor): The buffer to push.\\n\\n    Returns:\\n        bool: True if the buffer was successfully pushed, False otherwise.\\n    \"\"\"\\n\\n    return push(source, buffer)\\n\\n\\ndef _push_buffer_script(source, buffer):\\n    \"\"\"Push a buffer to an appsrc element.\\n\\n    This function is a TorchScript version of the `push` function. It is used to\\n    create a new function for each apprc event, which improves performance.\\n\\n    Args:\\n        source (Gst.Element): The appsrc element to push the buffer to.\\n        buffer (torch.Tensor): The buffer to push.\\n\\n    Returns:\\n        bool: True if the buffer was successfully pushed, False otherwise.\\n    \"\"\"\\n\\n    return torch.jit.script(push)(source, buffer)\\n\\n\\ndef _push_buffer_partial(source, buffer):\\n    \"\"\"Push a buffer to an appsrc element.\\n\\n    This function is a partial version of the `push` function. It is used to\\n    create a new function for each apprc event, which improves performance.\\n\\n    Args:\\n        source (Gst.Element): The appsrc element to push the buffer to.\\n        buffer (torch.Tensor): The buffer to push.\\n\\n    Returns:\\n        bool: True if the buffer was successfully pushed, False otherwise.\\n    \"\"\"\\n\\n    return functools.partial(push, source, buffer)\\n\\n\\ndef _push_buffer_jit_partial(source, buffer):\\n    \"\"\"Push a buffer to an appsrc element.\\n\\n    This function is a TorchScript partial version of the `push` function. It is\\n    used to create a new function for each apprc event, which improves\\n    performance.\\n\\n    Args:\\n        source (Gst.Element): The appsrc element to push the buffer to.\\n        buffer (torch.Tensor): The buffer to push.\\n\\n    Returns:\\n        bool: True if the buffer was successfully pushed, False otherwise.\\n    \"\"\"\\n\\n    return torch.jit.script(functools.partial(push, source, buffer))\\n\\n\\ndef get_push_function(event_type):\\n    \"\"\"Get the push function for a given apprc event type.\\n\\n    Args:\\n        event_type (str): The apprc event type.\\n\\n    Returns:\\n        function: The push function for the given event type.\\n    \"\"\"\\n\\n    if event_type == \\'end-of-stream\\':\\n        return _push_buffer_partial\\n    elif event_type == \\'push-buffer\\':\\n        return _push_buffer_jit_partial\\n    else:\\n        raise ValueError(\\'Invalid apprc event type: {}\\'.format(event_type))\\n\\n\\ndef push_buffer(source, buffer, event_type):\\n    \"\"\"Push a buffer to an appsrc element.\\n\\n    Args:\\n        source (Gst.Element): The appsrc element to push the buffer to.\\n        buffer (torch.Tensor): The buffer to push.\\n        event_type (str): The apprc event type.\\n\\n    Returns:\\n       ']\n"
     ]
    }
   ],
   "source": [
    "with open('palm_code_from_recommendations.csv', 'a+', encoding=\"utf-8\") as f_object:\n",
    "    for indx in range(2, 3):\n",
    "        print(indx)\n",
    "        secure_from_codeT5_recommendations = \\\n",
    "        palm_secure_code(df_code_t5_and_t5_recommendations['before_merge'][indx], \\\n",
    "                         df_code_t5_and_t5_recommendations['secure_results_codeT5'][indx])\n",
    "        \n",
    "        optimize_from_codeT5_recommendations = \\\n",
    "        palm_optimized_code(df_code_t5_and_t5_recommendations['before_merge'][indx], \\\n",
    "                         df_code_t5_and_t5_recommendations['optimized_results_codeT5'][indx])\n",
    "        \n",
    "        secure_from_T5_recommendations = \\\n",
    "        palm_secure_code(df_code_t5_and_t5_recommendations['before_merge'][indx], \\\n",
    "                         df_code_t5_and_t5_recommendations['secure_results_T5'][indx])\n",
    "\n",
    "        optimize_from_T5_recommendations = \\\n",
    "        palm_optimized_code(df_code_t5_and_t5_recommendations['before_merge'][indx], \\\n",
    "                         df_code_t5_and_t5_recommendations['optimized_results_T5'][indx])\n",
    "        \n",
    "        row = [df_code_t5_and_t5_recommendations[\"index\"][indx],\n",
    "               df_code_t5_and_t5_recommendations['after_merge'][indx], \n",
    "               df_code_t5_and_t5_recommendations['before_merge'][indx], \n",
    "               df_code_t5_and_t5_recommendations['secure_results_codeT5'][indx],\n",
    "               df_code_t5_and_t5_recommendations['optimized_results_codeT5'][indx], \n",
    "               df_code_t5_and_t5_recommendations['secure_results_T5'][indx] ,\n",
    "               df_code_t5_and_t5_recommendations['optimized_results_T5'][indx], \n",
    "               secure_from_codeT5_recommendations, \n",
    "               optimize_from_codeT5_recommendations, \n",
    "               secure_from_T5_recommendations, \n",
    "               optimize_from_T5_recommendations\n",
    "              ]\n",
    "        print(row)\n",
    "        writer_object = writer(f_object)\n",
    "        writer_object.writerow(row)\n",
    "        \n",
    "        f_object.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>after_merge</th>\n",
       "      <th>before_merge</th>\n",
       "      <th>secure_results_codeT5</th>\n",
       "      <th>optimized_results_codeT5</th>\n",
       "      <th>secure_results_T5</th>\n",
       "      <th>optimized_results_T5</th>\n",
       "      <th>secure_from_codeT5_recommendations</th>\n",
       "      <th>optimize_from_codeT5_recommendations</th>\n",
       "      <th>secure_from_T5_recommendations</th>\n",
       "      <th>optimize_from_T5_recommendations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102</td>\n",
       "      <td>def push(self, buffer_):\\n        if self....</td>\n",
       "      <td>def push(self, buffer_):\\n        if buffe...</td>\n",
       "      <td>1. Use `gst_source.emit('end-of-stream', buffe...</td>\n",
       "      <td>1. Use `gst_source.emit('end-of-stream', buffe...</td>\n",
       "      <td>1. Use functools.lru_cache to cache the result...</td>\n",
       "      <td>1. **Use functools.partial to avoid repeating ...</td>\n",
       "      <td>```python\\ndef push(self, buffer_):\\n    if bu...</td>\n",
       "      <td>```python\\ndef push(self, buffer_):\\n    if bu...</td>\n",
       "      <td>```python\\ndef push(self, buffer_):\\n    @func...</td>\n",
       "      <td>```python\\nimport functools\\nimport torch\\nimp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                        after_merge  \\\n",
       "0    102      def push(self, buffer_):\\n        if self....   \n",
       "\n",
       "                                        before_merge  \\\n",
       "0      def push(self, buffer_):\\n        if buffe...   \n",
       "\n",
       "                               secure_results_codeT5  \\\n",
       "0  1. Use `gst_source.emit('end-of-stream', buffe...   \n",
       "\n",
       "                            optimized_results_codeT5  \\\n",
       "0  1. Use `gst_source.emit('end-of-stream', buffe...   \n",
       "\n",
       "                                   secure_results_T5  \\\n",
       "0  1. Use functools.lru_cache to cache the result...   \n",
       "\n",
       "                                optimized_results_T5  \\\n",
       "0  1. **Use functools.partial to avoid repeating ...   \n",
       "\n",
       "                  secure_from_codeT5_recommendations  \\\n",
       "0  ```python\\ndef push(self, buffer_):\\n    if bu...   \n",
       "\n",
       "                optimize_from_codeT5_recommendations  \\\n",
       "0  ```python\\ndef push(self, buffer_):\\n    if bu...   \n",
       "\n",
       "                      secure_from_T5_recommendations  \\\n",
       "0  ```python\\ndef push(self, buffer_):\\n    @func...   \n",
       "\n",
       "                    optimize_from_T5_recommendations  \n",
       "0  ```python\\nimport functools\\nimport torch\\nimp...  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palm_df = pd.read_csv('palm_code_from_recommendations.csv')\n",
    "palm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging 0-99 and 100-200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv( 'palm_code_from_recommendations0_to_99.csv' )\n",
    "df2 = pd.read_csv('palm_code_from_recommendations_100_200.csv' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1,df2], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of      index                                        after_merge  \\\n",
       "0        0  def cmdb_get_mainline_object_topo(request, bk_...   \n",
       "1        1  def cc_search_object_attribute(request, obj_id...   \n",
       "2        2  def cc_search_create_object_attribute(request,...   \n",
       "3        3  def cc_search_topo(request, obj_id, category, ...   \n",
       "4        4  def job_get_script_list(request, biz_cc_id):\\r...   \n",
       "..     ...                                                ...   \n",
       "196    196  def main(args, error):\\n    \"\"\"\\n    Makes sur...   \n",
       "197    197  def get_string_resources(args):\\n    \"\"\" reads...   \n",
       "198    198  def get_domain_mx_list(domain):\\n    \"\"\"Return...   \n",
       "199    199      def authenticate(self, request, username=N...   \n",
       "200    200          def authenticate(self, *args, **kwargs...   \n",
       "\n",
       "                                          before_merge  \\\n",
       "0    def cmdb_get_mainline_object_topo(request, bk_...   \n",
       "1    def cc_search_object_attribute(request, obj_id...   \n",
       "2    def cc_search_create_object_attribute(request,...   \n",
       "3    def cc_search_topo(request, obj_id, category, ...   \n",
       "4    def job_get_script_list(request, biz_cc_id):\\r...   \n",
       "..                                                 ...   \n",
       "196  def main(args, error):\\n    \"\"\"\\n    Makes sur...   \n",
       "197  def get_string_resources(args):\\n    \"\"\" reads...   \n",
       "198  def get_domain_mx_list(domain):\\n    \"\"\"Return...   \n",
       "199      def authenticate(self, username=None, pass...   \n",
       "200          def authenticate(self, username, passw...   \n",
       "\n",
       "                                 secure_results_codeT5  \\\n",
       "0    1. Use `json.dumps()` to serialize the data in...   \n",
       "1    1. Use `get_client_by_request` to get the clie...   \n",
       "2    1. Use `get_client_by_request` to get the clie...   \n",
       "3    1. Use `json.dumps()` to serialize the respons...   \n",
       "4    1. Use `get_client_by_request` instead of `get...   \n",
       "..                                                 ...   \n",
       "196  1. Use `functools.lru_cache` to cache the resu...   \n",
       "197  1. Use `srcdir[name]` instead of `srcdir[name]...   \n",
       "198  1. Use `param_tools.get_global_parameter(\"cust...   \n",
       "199  1. Use `get_or_build_user()` instead of `get_o...   \n",
       "200  1. Use `super(LDAPBackend, self).authenticate(...   \n",
       "\n",
       "                              optimized_results_codeT5  \\\n",
       "0    1. **Use `functools.lru_cache` to cache the re...   \n",
       "1    1. **Use `json.dumps()` instead of `handle_api...   \n",
       "2    1. **Use `json.dumps()` to serialize the data ...   \n",
       "3    1. **Use `json.dumps()` instead of `json.dumps...   \n",
       "4    1. **Use `json.dumps()` instead of `handle_api...   \n",
       "..                                                 ...   \n",
       "196  1. Use `functools.lru_cache` to cache the resu...   \n",
       "197  1. Use `srcdir[name]` instead of `srcdir[name]...   \n",
       "198  1. Use `param_tools.get_global_parameter(\"cust...   \n",
       "199  1. Use `functools.lru_cache` to cache the resu...   \n",
       "200  1. **Use `functools.lru_cache` to cache the re...   \n",
       "\n",
       "                                     secure_results_T5  \\\n",
       "0    1. Use functools.lru_cache to cache the result...   \n",
       "1    1. Use functools.lru_cache to cache the result...   \n",
       "2    1. Use functools.lru_cache to cache the result...   \n",
       "3    1. Use functools.lru_cache to cache the result...   \n",
       "4    1. Use functools.lru_cache to cache the result...   \n",
       "..                                                 ...   \n",
       "196  1. Use functools.lru_cache to cache the result...   \n",
       "197  1. Use functools.lru_cache to cache the result...   \n",
       "198  1. Use functools.lru_cache to cache the result...   \n",
       "199  1. Use functools.lru_cache to cache the result...   \n",
       "200  1. Use functools.lru_cache to cache the result...   \n",
       "\n",
       "                                  optimized_results_T5  \\\n",
       "0    1. **Use functools.lru_cache to cache the resu...   \n",
       "1    1. Use functools.lru_cache to cache the result...   \n",
       "2    1. Use functools.lru_cache to cache the result...   \n",
       "3    1. Use functools.lru_cache to cache the result...   \n",
       "4    1. **Use functools.lru_cache to cache the resu...   \n",
       "..                                                 ...   \n",
       "196  1. **Use functools.lru_cache to cache the resu...   \n",
       "197  1. Use functools.lru_cache to cache the result...   \n",
       "198  1. Use functools.lru_cache to cache the result...   \n",
       "199  1. Use smtplib.SMTP_SSL() instead of smtplib.S...   \n",
       "200  1. **Use functools.lru_cache to cache the resu...   \n",
       "\n",
       "                    secure_from_codeT5_recommendations  \\\n",
       "0    ```python\\r\\ndef cmdb_get_mainline_object_topo...   \n",
       "1    ```python\\r\\ndef cc_search_object_attribute(re...   \n",
       "2    ```python\\r\\ndef cc_search_create_object_attri...   \n",
       "3    ```python\\r\\ndef cc_search_topo(request, obj_i...   \n",
       "4    ```python\\r\\ndef job_get_script_list(request, ...   \n",
       "..                                                 ...   \n",
       "196  ```python\\ndef main(args, error):\\n    \"\"\"\\n  ...   \n",
       "197  _read_read_read_read_read_read_read_read_read_...   \n",
       "198  ```python\\ndef get_domain_mx_list(domain):\\n  ...   \n",
       "199                                     000_Didnt Work   \n",
       "200  ```python\\ndef authenticate(self, username, pa...   \n",
       "\n",
       "                  optimize_from_codeT5_recommendations  \\\n",
       "0    ```python\\r\\ndef cmdb_get_mainline_object_topo...   \n",
       "1    ```python\\r\\ndef cc_search_object_attribute(re...   \n",
       "2    ```python\\r\\ndef cc_search_create_object_attri...   \n",
       "3    ```python\\r\\ndef cc_search_topo(request, obj_i...   \n",
       "4    ```python\\r\\ndef job_get_script_list(request, ...   \n",
       "..                                                 ...   \n",
       "196  ```python\\ndef main(args, error):\\n    \"\"\"\\n  ...   \n",
       "197  _read_read_read_read ```python\\ndef get_string...   \n",
       "198  ```python\\ndef get_domain_mx_list(domain):\\n  ...   \n",
       "199  ```python\\nimport functools\\nimport smtplib\\ni...   \n",
       "200  ```python\\nfrom functools import lru_cache\\nfr...   \n",
       "\n",
       "                        secure_from_T5_recommendations  \\\n",
       "0    ```python\\r\\ndef cmdb_get_mainline_object_topo...   \n",
       "1    ```python\\r\\ndef cc_search_object_attribute(re...   \n",
       "2    ```python\\r\\ndef cc_search_create_object_attri...   \n",
       "3    save def cc_search_topo(request, obj_id, categ...   \n",
       "4    ```python\\r\\ndef job_get_script_list(request, ...   \n",
       "..                                                 ...   \n",
       "196  ```python\\ndef main(args, error):\\n    \"\"\"\\n  ...   \n",
       "197  ```python\\ndef get_string_resources(args):\\n  ...   \n",
       "198  ```python\\ndef get_domain_mx_list(domain):\\n  ...   \n",
       "199  ```python\\nfrom functools import lru_cache\\n\\n...   \n",
       "200  ```python\\nimport functools\\nimport torch.jit\\...   \n",
       "\n",
       "                      optimize_from_T5_recommendations  \n",
       "0    ** This will make the code more concise and ea...  \n",
       "1    ```python\\r\\ndef cc_search_object_attribute(re...  \n",
       "2    ```python\\r\\ndef cc_search_create_object_attri...  \n",
       "3    optimized ```python\\r\\ndef cc_search_topo(requ...  \n",
       "4    ```python\\r\\ndef job_get_script_list(request, ...  \n",
       "..                                                 ...  \n",
       "196  ** This will make the code more concise and ea...  \n",
       "197  ```python\\nimport functools\\nimport torch\\n\\nf...  \n",
       "198  ```python\\nfrom functools import lru_cache\\nfr...  \n",
       "199  ```python\\ndef authenticate(self, username=Non...  \n",
       "200  ```python\\nimport functools\\nfrom torch.jit im...  \n",
       "\n",
       "[201 rows x 11 columns]>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>after_merge</th>\n",
       "      <th>before_merge</th>\n",
       "      <th>secure_results_codeT5</th>\n",
       "      <th>optimized_results_codeT5</th>\n",
       "      <th>secure_results_T5</th>\n",
       "      <th>optimized_results_T5</th>\n",
       "      <th>secure_from_codeT5_recommendations</th>\n",
       "      <th>optimize_from_codeT5_recommendations</th>\n",
       "      <th>secure_from_T5_recommendations</th>\n",
       "      <th>optimize_from_T5_recommendations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>110</td>\n",
       "      <td>def _retrieve(source_key, target_key, targ...</td>\n",
       "      <td>def _retrieve(source_key, target_key, targ...</td>\n",
       "      <td>1. Use `data[source_key] = data[source_key]` i...</td>\n",
       "      <td>1. Use `data.get()` instead of `data[source_ke...</td>\n",
       "      <td>1. Use source_key instead of source_key to sec...</td>\n",
       "      <td>1. **Use functools.lru_cache to cache the resu...</td>\n",
       "      <td>000_Didnt Work</td>\n",
       "      <td>```python\\ndef _retrieve(source_key, target_ke...</td>\n",
       "      <td>000_Didnt Work</td>\n",
       "      <td>```python\\nfrom functools import lru_cache\\n\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                        after_merge  \\\n",
       "110    110      def _retrieve(source_key, target_key, targ...   \n",
       "\n",
       "                                          before_merge  \\\n",
       "110      def _retrieve(source_key, target_key, targ...   \n",
       "\n",
       "                                 secure_results_codeT5  \\\n",
       "110  1. Use `data[source_key] = data[source_key]` i...   \n",
       "\n",
       "                              optimized_results_codeT5  \\\n",
       "110  1. Use `data.get()` instead of `data[source_ke...   \n",
       "\n",
       "                                     secure_results_T5  \\\n",
       "110  1. Use source_key instead of source_key to sec...   \n",
       "\n",
       "                                  optimized_results_T5  \\\n",
       "110  1. **Use functools.lru_cache to cache the resu...   \n",
       "\n",
       "    secure_from_codeT5_recommendations  \\\n",
       "110                     000_Didnt Work   \n",
       "\n",
       "                  optimize_from_codeT5_recommendations  \\\n",
       "110  ```python\\ndef _retrieve(source_key, target_ke...   \n",
       "\n",
       "    secure_from_T5_recommendations  \\\n",
       "110                 000_Didnt Work   \n",
       "\n",
       "                      optimize_from_T5_recommendations  \n",
       "110  ```python\\nfrom functools import lru_cache\\n\\n...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[110:111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"palm_code_from_reccomendations_0_to_200\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
